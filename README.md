# FMA: A Dataset For Music Analysis

[MichaÃ«l Defferrard](https://deff.ch),
[Kirell Benzi](https://www.kirellbenzi.com),
[Pierre Vandergheynst](https://people.epfl.ch/pierre.vandergheynst),
[Xavier Bresson](https://www.ntu.edu.sg/home/xbresson), \
International Society for Music Information Retrieval Conference (ISMIR), 2017.

> We introduce the Free Music Archive (FMA), an open and easily accessible dataset suitable for evaluating several tasks in MIR, a field concerned with browsing, searching, and organizing large music collections.
> The community's growing interest in feature and end-to-end learning is however restrained by the limited availability of large audio datasets.
> The FMA aims to overcome this hurdle by providing 917 GiB and 343 days of Creative Commons-licensed audio from 106,574 tracks from 16,341 artists and 14,854 albums, arranged in a hierarchical taxonomy of 161 genres.
> It provides full-length and high-quality audio, pre-computed features, together with track- and user-level metadata, tags, and free-form text such as biographies.
> We here describe the dataset and how it was created, propose a train/validation/test split and three subsets, discuss some suitable MIR tasks, and evaluate some baselines for genre recognition.
> Code, data, and usage examples are available at https://github.com/mdeff/fma.

## Resources

* PDF: [arXiv](https://arxiv.org/abs/1612.01840), [ISMIR](https://archives.ismir.net/ismir2017/paper/000075.pdf), [EPFL](https://infoscience.epfl.ch/record/227512).
* Code: <https://github.com/mdeff/fma>.
* Presentation: [slides](https://doi.org/10.5281/zenodo.1066119) and [poster](https://doi.org/10.5281/zenodo.1035847).
